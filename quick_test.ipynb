{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils import Indexer\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = 'data/links.csv'\n",
    "metadata = 'data/movies_metadata.csv'\n",
    "credit = 'data/credits.csv'\n",
    "rating = 'data/ratings.csv'\n",
    "\n",
    "train_dir = 'processed_data/rating_train.csv'\n",
    "test_dir = 'processed_data/rating_test.csv'\n",
    "\n",
    "overview = 'processed_data/overviews.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   mId                                           overview\n",
       "0    0  Led by Woody, Andy's toys live happily in his ...\n",
       "1    1  When siblings Judy and Peter discover an encha...\n",
       "2    2  A family wedding reignites the ancient feud be...\n",
       "3    3  Cheated on, mistreated and stepped on, the wom...\n",
       "4    4  Just when George Banks has recovered from his ..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mId</th>\n      <th>overview</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Led by Woody, Andy's toys live happily in his ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>When siblings Judy and Peter discover an encha...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>A family wedding reignites the ancient feud be...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Cheated on, mistreated and stepped on, the wom...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Just when George Banks has recovered from his ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 161
    }
   ],
   "source": [
    "data = pd.read_csv(overview)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test sample: [['led', 'by', 'woody,', \"andy's\", 'toys', 'live', 'happily', 'his', 'room', 'until', \"andy's\", 'birthday', 'brings', 'buzz', 'lightyear', 'onto', 'scene.', 'afraid', 'losing', 'his', 'place', \"andy's\", 'heart,', 'woody', 'plots', 'against', 'buzz.', 'but', 'when', 'circumstances', 'separate', 'buzz', 'woody', 'from', 'their', 'owner,', 'duo', 'eventually', 'learns', 'put', 'aside', 'their', 'differences']]\n"
     ]
    }
   ],
   "source": [
    "# Infer a vector for a new doc\n",
    "test = [\"Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences\"]\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in test]\n",
    "print(f\"test sample: {texts}\")\n",
    "vector = model.infer_vector(texts[0])\n",
    "print(f\"vector: {vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of sentence: 45463\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[\"Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.\",\n",
       " \"When siblings Judy and Peter discover an enchanted board game that opens the door to a magical world, they unwittingly invite Alan -- an adult who's been trapped inside the game for 26 years -- into their living room. Alan's only hope for freedom is to finish the game, which proves risky as all three find themselves running from giant rhinoceroses, evil monkeys and other terrifying creatures.\"]"
      ]
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "source": [
    "overview_sentences = data['overview'].astype(str)\n",
    "mId = data['mId'].astype(int)\n",
    "print(\"Number of sentence: %d\"%(len(overview_sentences)) )\n",
    "type(overview_sentence)\n",
    "overview_sentence[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['led', 'by', 'woody,', \"andy's\", 'toys', 'live', 'happily', 'his', 'room', 'until', \"andy's\", 'birthday', 'brings', 'buzz', 'lightyear', 'onto', 'scene.', 'afraid', 'losing', 'his', 'place', \"andy's\", 'heart,', 'woody', 'plots', 'against', 'buzz.', 'but', 'when', 'circumstances', 'separate', 'buzz', 'woody', 'from', 'their', 'owner,', 'duo', 'eventually', 'learns', 'put', 'aside', 'their', 'differences.']]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-57b2d7c4fd23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# pprint.pprint(processed_corpus)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcommon_texts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc2vec\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTaggedDocument\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mTaggedDocument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmId\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# You need the [] for mId[i], because both input need to be iterable, e.g., str, list, dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "# Some preprocessing\n",
    "stoplist = set('for a of the and to in'.split(' '))\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in overview_sentences]\n",
    "print(texts[:1])\n",
    "\n",
    "# Count word frequencies\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "# Only keep words that appear more than once\n",
    "processed_corpus = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "# pprint.pprint(processed_corpus)\n",
    "\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "documents = [TaggedDocument(texts[i], [mId[i]]) for i in range(len(texts))] # You need the [] for mId[i], because both input need to be iterable, e.g., str, list, dict\n",
    "print(type(documents))\n",
    "print(f\"Shape of document: {len(documents)}\")\n",
    "print(f\"Sample of documents: {documents[:2]}\")\n",
    "model = Doc2Vec(iter(documents), vector_size=5, window=2, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parsing the overview sentences\n",
    "overview_sentences = []\n",
    "for overview_sentences, mId in zip(overview_sentences, mId):\n",
    "    print(overview_sentences)\n",
    "    # overview_sentences.append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize the sentences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab_size = 10000 # Size of word corpus\n",
    "embedding_dim = 16 # dimension of output vector\n",
    "max_length = 32 # Maximum length of token\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<ooV>'\n",
    "data_size = data.shape[0] # Size of training dataset\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(overview_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "# print(word_index)\n",
    "overview_sequences = tokenizer.texts_to_sequences(overview_sentences)\n",
    "overview_padded = pad_sequences(overview_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "# print(\"\\nWord Index = \" , word_index)\n",
    "# print(f\"Sequences[:3]: {overview_sentence[:3]}\")\n",
    "print(\"Padded Sequences:\")\n",
    "print(overview_padded[:, :3])\n",
    "print(overview_padded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_sequences1 = tokenizer.texts_to_matrix(overview_sentences, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Padded Sequences:\")\n",
    "print(overview_sequences1[:, :3])\n",
    "print(overview_sequences1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.arange(10)\n",
    "x2 = x1*2\n",
    "y = x1*2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "x1 = np.arange(10)\n",
    "x2 = x1*2\n",
    "y = x1*2\n",
    "\n",
    "plt.figure(figsize=(12.2, 4.5)) # width=12.2in, height=4.5in\n",
    "plt.scatter(x1, y, color='green', label='Line1')\n",
    "plt.scatter(x2, y, color='red', label='Line2')\n",
    "plt.plot(x1, y, alpha=0.35) #\tPlot y versus x as lines and/or markers.\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(label='Title of this figure')\n",
    "plt.xlabel('X label', fontsize=18)\n",
    "plt.ylabel('Y label', fontsize=18)\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data = [[30, 25, 50, 20],\n",
    "[40, 23, 51, 17],\n",
    "[35, 22, 45, 19]]\n",
    "X = ['2011', '2012', '2013', '2014']\n",
    "fig = plt.figure()\n",
    "# ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(X, data[0], color = 'b', width = 0.25)\n",
    "ax.bar(X, data[1], color = 'g', width = 0.25)\n",
    "ax.bar(X, data[2], color = 'r', width = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# df = pd.DataFrame(np.array([[94.13, 94.01], [44.91, 43.97]]),\n",
    "#     index = [\"Fashion MNIST\", \"Cifar100\"],\n",
    "#     columns=pd.Index(['GPU',' CPU'], name='Device')\n",
    "# )\n",
    "df = pd.DataFrame({'GPU': [94.01, 43.97],\n",
    "        'CPU': [94.01, 44.91]},\n",
    "        index=[\"Fashion MNIST\", \"Cifar100\"]\n",
    ")\n",
    "\n",
    "df.plot.bar(xlabel='dataset', ylabel='Acc(%)', title='DNN Model1: Flatten()-->Dense(128)-->Dense(10)', rot=30)\n",
    "\n",
    "# acc = [[94.13, 94.01], [44.91, 43.97]] # CPU acc and GPU acc for Fashion MNIST and Cifar100\n",
    "# time = [[2.812, 2.871], [1.1, 2.2]]\n",
    "# X = np.arange(4)\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_axes([0,0,1,1])\n",
    "# ax.bar(X + 0.00, data[0], color = 'b', width = 0.25)\n",
    "# ax.bar(X + 0.25, data[1], color = 'g', width = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'GPU': [95.5, 89.06],\n",
    "        'CPU': [96.77, 88.61]},\n",
    "        index=[\"Fashion MNIST\", \"Cifar100\"]\n",
    ")\n",
    "\n",
    "df.plot.bar(xlabel='dataset', ylabel='Acc(%)', title='DNN Model2: Con2D(32)-->Conv2D(64)-->Flatten()-->Dense(128)-->Dense(10)', rot=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'GPU': [2.871, 2.2],\n",
    "        'CPU': [2.812, 1.1]},\n",
    "        index=[\"Fashion MNIST\", \"Cifar100\"]\n",
    ")\n",
    "\n",
    "df.plot.bar(xlabel='dataset', ylabel='Time(sec/epoch)', title='DNN Model1: Flatten()-->Dense(128)-->Dense(10)', rot=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'GPU': [4.2, 3.3],\n",
    "        'CPU': [14.7, 11.9]},\n",
    "        index=[\"Fashion MNIST\", \"Cifar100\"]\n",
    ")\n",
    "\n",
    "df.plot.bar(xlabel='dataset', ylabel='Time(sec/epoch)', title='DNN Model2: Con2D(32)-->Conv2D(64)-->Flatten()-->Dense(128)-->Dense(10)', rot=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'GPU': [3022, 3429],\n",
    "        'CPU': [23679, 9526]},\n",
    "        index=[\"VGG19\", \"ResNet50\"]\n",
    ")\n",
    "\n",
    "df.plot.bar(xlabel='DNN Model', ylabel='Time(sec/epoch)', title='What is the Best DNN model for IMDB-Wiki  Dataset(on similar ACC)', rot=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Time(sec/epoch)': [184, 99, 72, 78, 67],\n",
    "        'Throughput(sec/step)': [2, 0.988, 0.719, 0.779, 0.668]},\n",
    "        index=[2, 4, 8, 16, 28]\n",
    ")\n",
    "\n",
    "df.plot.bar(xlabel='Cores', ylabel='Time(sec)', title='ResNet50 on IMDB-Wiki Dataest(on CPU and batch_size=32)', rot=30, subplots=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Time(sec/epoch)': [8, 10, 37, 72, 74, 361],\n",
    "        # 'Throughput(step/ms)': [84, 95, 374, 715, 737, 4000]},\n",
    "        'Throughput(sec/step)': [0.084, 0.095, 0.374, 0.715, 0.737, 4]},\n",
    "        index=[2, 4, 8, 16, 32, 64]\n",
    ")\n",
    "\n",
    "df.plot.bar(xlabel='Batch size', ylabel='Time(sec)', title='ResNet50 on IMDB-Wiki Dataest(on GPU and cores=28)', rot=30, subplots=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}